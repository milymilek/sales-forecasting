{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing, pipeline, compose, model_selection, metrics\n",
    "from typing import Callable\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sales_forecasting.utils import timeseries_split, kfold_timeseries_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\".data/df_train.parquet\")\n",
    "df_test = pd.read_parquet(\".data/df_test.parquet\")\n",
    "df_full = pd.read_parquet(\".data/df_full.parquet\")\n",
    "df_items = pd.read_csv(\".data/items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_block_num_date_month_map = df_train[['date_block_num', 'date']] \\\n",
    "    .assign(date_month=df_train['date'].dt.month - 1) \\\n",
    "    .drop_duplicates(subset=[\"date_block_num\", \"date_month\"])[['date_block_num', 'date_month']] \\\n",
    "    .set_index('date_block_num')['date_month'].to_dict()\n",
    "\n",
    "df_train_monthly_sum_index = df_train.groupby([\"shop_id\", \"item_id\", \"date_block_num\"]) \\\n",
    "    .apply(lambda x: x['item_cnt_day'].sum()) \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={0: \"item_cnt_month\"})\n",
    "df_train_monthly_features = df_train.drop(columns=[\"date\", \"item_price\", \"item_cnt_day\", \"item_cnt_day_clipped\"]).drop_duplicates()\n",
    "df_train_monthly_sum = df_train_monthly_sum_index.merge(df_train_monthly_features, on=['shop_id', 'item_id', 'date_block_num'])\n",
    "df_train_monthly_sum = df_train_monthly_sum.assign(item_cnt_month_clipped=df_train_monthly_sum[\"item_cnt_month\"].clip(0, 20))\n",
    "df_train_monthly_sum['date_month'] = df_train_monthly_sum['date_block_num'].map(date_block_num_date_month_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train_monthly_sum \\\n",
    "    .sort_values([\"date_block_num\", \"shop_id\", \"item_id\"]) \\\n",
    "    .reset_index(drop=True)\n",
    "df_test = df_test \\\n",
    "    .sort_values([\"date_block_num\", \"shop_id\", \"item_id\"]) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_item_cnt_month(df, max_month):\n",
    "    columns = ['date_block_num', 'item_cnt_month']\n",
    "    min_month = df['date_block_num'].min()\n",
    "\n",
    "    date_col_data = np.arange(0, max_month + 1, dtype=int)\n",
    "    item_cnt_month_col_data = np.zeros_like(date_col_data, dtype=float)\n",
    "    item_cnt_month_col_data[df['date_block_num'].values] = df['item_cnt_month'].values\n",
    "    #date_col_data = date_col_data[min_month:max_month]\n",
    "    #item_cnt_month_col_data = item_cnt_month_col_data[min_month:max_month]\n",
    "    oversampled = pd.DataFrame(np.column_stack([date_col_data, item_cnt_month_col_data]), columns=columns)\n",
    "\n",
    "    return oversampled\n",
    "\n",
    "df_oversample = df[['date_block_num', 'shop_id', 'item_id', 'item_cnt_month']].sort_values([\"shop_id\", \"item_id\", \"date_block_num\"])\n",
    "df_oversample = df_oversample \\\n",
    "    .groupby([\"shop_id\", \"item_id\"]) \\\n",
    "    .apply(oversample_item_cnt_month, max_month=df_oversample['date_block_num'].max()) \\\n",
    "    .reset_index(level=-1, drop=True) \\\n",
    "    .reset_index() \\\n",
    "    .astype({\"date_block_num\": np.int64, \"item_cnt_month\": np.float64})\n",
    "# df_oversample.to_parquet(\"df_oversampled.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid = df_oversample[(df_oversample.date_block_num == 33) & (df_oversample.item_cnt_month != 0.0)]\n",
    "\n",
    "# for i in df_valid.sort_values([\"shop_id\", \"item_id\", \"date_block_num\"]).head(40).iterrows():\n",
    "#     id, row = i\n",
    "\n",
    "#     display(df_oversample[(df_oversample.shop_id == row.shop_id) & (df_oversample.item_id == row.item_id)])\n",
    "#     display(df_valid[(df_valid.shop_id == row.shop_id) & (df_valid.item_id == row.item_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df_test.sort_values([\"shop_id\", \"item_id\", \"date_block_num\"]).head(40).iterrows():\n",
    "#     id, row = i\n",
    "\n",
    "#     display(df_oversample[(df_oversample.shop_id == row.shop_id) & (df_oversample.item_id == row.item_id)])\n",
    "#     display(df_test[(df_test.shop_id == row.shop_id) & (df_test.item_id == row.item_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversample = df_oversample.merge(df_train[['shop_id', \"item_id\", \"item_category_id\"]].drop_duplicates(), on=[\"shop_id\", \"item_id\"], how='left')\n",
    "df_oversample['date_month'] = df_oversample['date_block_num'].map(date_block_num_date_month_map)\n",
    "df_oversample['month_sin'] = np.sin(np.pi / 12 * (df_oversample['date_month']))\n",
    "df_oversample['month_cos'] = np.cos(np.pi / 12 * (df_oversample['date_month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_features_list = list(range(1, 3))\n",
    "for i in lagged_features_list:\n",
    "    df_oversample[f\"lagged_date_block_num_{i}\"] = df_oversample.groupby([\"shop_id\", \"item_id\"])[\"date_block_num\"].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oversample[(df_oversample.shop_id == 0) & (df_oversample.shop_id == 30)].groupby([\"shop_id\", \"item_id\"]).apply(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_transformed = ohe.transform(df_test[['shop_id', 'item_id', 'item_category_id']])\n",
    "\n",
    "test_data = lgb.Dataset(df_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gbm.predict(df_test_transformed, num_iteration=gbm.best_iteration)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw = pd.read_csv(\".data/test.csv\")\n",
    "df_test_predictions = df_test.assign(item_cnt_month=y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test_raw.merge(df_test_predictions, on=[\"shop_id\", \"item_id\"])[['ID', 'item_cnt_month']]\n",
    "submission.to_csv(\".data/submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[['item_cnt_month']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = ['shop_id', 'item_id', 'item_category_id']\n",
    "ohe = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(df[ohe_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(df[ohe_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(1609124, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming `encoded_data` is your sparse one-hot encoded data,\n",
    "# and `numerical_data` is a numpy array with shape (n_samples, 2)\n",
    "\n",
    "# Combine sparse one-hot encoded data with dense numerical data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgb(df, params, k_min=1, k_max=33):\n",
    "    ohe_cols = ['shop_id', 'item_id', 'item_category_id']\n",
    "    ohe = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe.fit(df[ohe_cols])\n",
    "\n",
    "    df['month_sin'] = np.sin(np.pi / 12 * (df['date_month']))\n",
    "    df['month_cos'] = np.cos(np.pi / 12 * (df['date_month']))\n",
    "\n",
    "    for i, (train_split, test_split) in enumerate(kfold_timeseries_split(df, col='date_block_num', k_min=k_min, k_max=k_max)):\n",
    "        print(f\"\\n\\nFold: {i}\")\n",
    "        # display(train_split)\n",
    "        # display(test_split)\n",
    "        train_transformed = ohe.transform(train_split[ohe_cols])\n",
    "        test_transformed = ohe.transform(test_split[ohe_cols])\n",
    "\n",
    "        train_combined = hstack([train_transformed, train_split[['month_sin', 'month_cos'] + [\"prev_item_price_agg__local\", \"is_prev_item_price__local\", \"prev_item_price_agg__global\", \"is_prev_item_price__global\"]]]).tocsr()\n",
    "        test_combined = hstack([test_transformed, test_split[['month_sin', 'month_cos'] + [\"prev_item_price_agg__local\", \"is_prev_item_price__local\", \"prev_item_price_agg__global\", \"is_prev_item_price__global\"]]]).tocsr()\n",
    "\n",
    "        train_data = lgb.Dataset(train_combined, label=train_split['item_cnt_month_clipped'])\n",
    "        test_data = lgb.Dataset(test_combined, label=test_split['item_cnt_month_clipped'], reference=train_data)\n",
    "        \n",
    "        gbm = lgb.train(params, train_data, num_boost_round=100, valid_sets=[train_data, test_data])\n",
    "\n",
    "        print(gbm.best_score)\n",
    "        \n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_features_merged = df.merge(feature_store_previous_price, on=['date_block_num', 'shop_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_features_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'sales' is your target column, 'shop_id', 'product_id', and 'date' are identifiers\n",
    "sales_df = df_price_features_merged.sort_values(by=['shop_id', 'item_id', 'date_block_num'])\n",
    "for lag in range(1, 4):  # You can experiment with the lag range\n",
    "    sales_df[f'sales_lag_{lag}'] = sales_df.groupby(['shop_id', 'item_id'])['item_cnt_month_clipped'].shift(lag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_features_merged.groupby(['shop_id', 'item_id'])['date_block_num'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = df_price_features_merged[(df_price_features_merged.shop_id == 52) & (df_price_features_merged.item_id == 1905)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.groupby([\"shop_id\", \"item_id\"])['item_cnt_month'].rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 127,\n",
    "    'max_depth': 40,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "model_columns = ['date_block_num', 'shop_id', 'item_id', 'item_category_id', 'date_month', 'item_cnt_month_clipped'] + [\"prev_item_price_agg__local\", \"is_prev_item_price__local\", \"prev_item_price_agg__global\", \"is_prev_item_price__global\"]\n",
    "gbm = train_lgb(df_price_features_merged[model_columns], params, k_min=33, k_max=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.pandas_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_n_last(x: np.ndarray, n: int = 3) -> float:\n",
    "    return x[-min(n, x.size):].mean()\n",
    "\n",
    "def aggregate_monthly(df: pd.DataFrame, agg_fn: Callable, agg_scope_name: str) -> pd.DataFrame:\n",
    "    new_cols = [f'prev_item_price_agg__{agg_scope_name}', f'is_prev_item_price__{agg_scope_name}']\n",
    "    #display(df)\n",
    "    months_sales = df['date_block_num'].unique()\n",
    "    #print(months_sales)\n",
    "    mapping = {months_sales[0]: np.nan}\n",
    "    for i in range(1, len(months_sales)):\n",
    "        i_date_block_num = months_sales[i]\n",
    "        #display(df[df['date_block_num'] < i_date_block_num])\n",
    "        mapping[i_date_block_num] = agg_fn(df[df['date_block_num'] < i_date_block_num]['item_price'])\n",
    "\n",
    "    df[new_cols[0]] = df['date_block_num'].map(mapping)\n",
    "    df[new_cols[1]] = df['date_block_num'].map({k: int(np.isnan(v)) for k,v in mapping.items()})\n",
    "\n",
    "    display()\n",
    "\n",
    "    return df[[\"date_block_num\", *new_cols]].reset_index(drop=True)\n",
    "\n",
    "def build_monthly_item_price_features(df: pd.DataFrame, agg_cols: list[str], agg_fun: Callable) -> pd.DataFrame:\n",
    "    agg_scope_name = {\"shop_id\": \"local\", \"item_id\": \"global\"}[agg_cols[0]]\n",
    "    new_features = df.groupby(agg_cols) \\\n",
    "        .apply(aggregate_monthly, agg_fn=agg_fun, agg_scope_name=agg_scope_name) \\\n",
    "        .reset_index(level=-1, drop=True).reset_index() \\\n",
    "        .drop_duplicates()\n",
    "    return pd.merge(df, new_features, on=[*agg_cols, \"date_block_num\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shop_5 = df_train[df_train.shop_id < 10]\n",
    "# df_shop_5 = build_monthly_item_price_features(df_shop_5, agg_cols=[\"shop_id\", \"item_id\"], agg_fun=np.mean)\n",
    "# df_shop_5 = build_monthly_item_price_features(df_shop_5, agg_cols=[\"item_id\"], agg_fun=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shop_price_feat = build_monthly_item_price_features(df_train, agg_cols=[\"shop_id\", \"item_id\"], agg_fun=np.mean)\n",
    "df_shop_price_feat = build_monthly_item_price_features(df_shop_price_feat, agg_cols=[\"item_id\"], agg_fun=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_previous_price = df_shop_price_feat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_previous_price = feature_store_previous_price[['date_block_num', 'shop_id', 'item_id', 'prev_item_price_agg__local', 'is_prev_item_price__local', 'prev_item_price_agg__global', 'is_prev_item_price__global']] \\\n",
    "    .drop_duplicates() \\\n",
    "    .sort_values(['date_block_num', 'shop_id', 'item_id']) \\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.merge(feature_store_previous_price, on=['date_block_num', 'shop_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_previous_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store_previous_price[feature_store_previous_price.is_prev_item_price__local == 0]['prev_item_price_agg__local'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_month_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_features = df.copy()\n",
    "\n",
    "    df_features['month_sin'] = np.sin(np.pi / 12 * (df['date'].dt.month - 1))\n",
    "    df_features['month_cos'] = np.cos(np.pi / 12 * (df['date'].dt.month - 1))\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_month_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_cnt_day'] = df['item_cnt_day'].clip(0, 20)\n",
    "df = df[['date_block_num', 'shop_id', 'item_id', 'item_category_id', 'item_cnt_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"item_cnt_day\"])\n",
    "y = df[['item_cnt_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = []\n",
    "cat_columns = ['shop_id', 'item_id', 'item_category_id']\n",
    "\n",
    "preprocessor = compose.ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', preprocessing.StandardScaler(), num_columns),\n",
    "        ('cat', preprocessing.OneHotEncoder(), cat_columns)\n",
    "    ])\n",
    "\n",
    "pipeline = pipeline.Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = timeseries_split(X, col=\"date_block_num\", continuous=False)\n",
    "y_train, y_valid, y_test = y.iloc[X_train.index], y.iloc[X_valid.index], y.iloc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pipeline.transform(X_train)\n",
    "X_valid_transformed = pipeline.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pd.DataFrame(data=enc.transform(X).toarray(), columns=enc.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = enc.transform(X_train)\n",
    "X_test_transformed = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train_transformed, label=y_train)\n",
    "test_data = lgb.Dataset(X_test_transformed, label=y_test, reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "gbm = lgb.train(params, train_data, num_boost_round=100, valid_sets=[train_data, test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_train_transformed, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
