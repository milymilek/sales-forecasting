{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sales_forecasting.utils import timeseries_split\n",
    "from sales_forecasting.plot import plot_timeseries, plot_feature_importance\n",
    "from sales_forecasting.features import col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\".data/df_agg_monthly_oversampled.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, valid_split = timeseries_split(df, max_month=33, col='date_block_num', continuous=False)\n",
    "train_test_split, test_split = timeseries_split(df, max_month=34, col='date_block_num', continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'item_cnt_month'\n",
    "train_target, valid_target = train_split[target_col].clip(0, 20), valid_split[target_col].clip(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [target_col, 'date_block_num']\n",
    "X_train, X_valid = train_split.drop(columns=cols_to_drop), valid_split.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = train_split.drop(columns=['shop_id', 'item_id']), valid_split.drop(columns=['shop_id', 'item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = ['city_id', 'item_category_id', 'general_item_category_id', 'date_month']\n",
    "num_cols = list(np.setdiff1d(X_train.columns, ohe_cols))\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', preprocessing.StandardScaler(), num_cols),\n",
    "        ('cat', preprocessing.OneHotEncoder(handle_unknown='ignore'), ohe_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_valid_preprocessed = preprocessor.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesPredictionMLPModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: list[int], dropout_rate: float, batch_norm: bool = True):\n",
    "        super(SalesPredictionMLPModel, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        dims = [input_dim] + hidden_dim\n",
    "        for in_dim, out_dim in zip(dims, dims[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(out_dim))\n",
    "            layers.extend([nn.Dropout(p=dropout_rate), nn.ReLU()])\n",
    "        layers.append(nn.Linear(dims[-1], 1))\n",
    "\n",
    "        self.ff = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return self.ff(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesMLPDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X.toarray(), dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_dataset = SalesMLPDataset(X_train_preprocessed, train_target)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = SalesMLPDataset(X_valid_preprocessed, valid_target)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dropout_rate = 0.2\n",
    "input_dim = X_train_preprocessed.shape[1]\n",
    "hidden_dim = [64, 32]\n",
    "lr = 1e-5\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = SalesPredictionMLPModel(input_dim, hidden_dim, dropout_rate=dropout_rate).to(device)\n",
    "criterion = F.mse_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def train(\n",
    "    model: nn.Module, \n",
    "    loss_fn: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    device: torch.device, \n",
    "    epoch: int, \n",
    "    print_every: None | int = None\n",
    ") -> float:\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_item = loss.detach().cpu().item()\n",
    "\n",
    "        if print_every is not None and batch_idx % print_every == 0:\n",
    "            print(\n",
    "                \"Train (Batch): [{}/{} ({:.0f}%)]\\tTrain Loss: {:.4f} \\tTrain RMSE: {:.4f}\".format(\n",
    "                    batch_idx * len(data), len(train_loader.dataset), 100.0 * batch_idx / len(train_loader), loss_item, loss_item ** 0.5\n",
    "                ) # type: ignore\n",
    "            )\n",
    "        train_loss += loss_item\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: nn.Module, \n",
    "    loss_fn: Callable,\n",
    "    device: torch.device,\n",
    "    test_loader: DataLoader, \n",
    "    print_every: None | int = None\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss =  loss_fn(output, target, reduction=\"sum\")\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    if print_every is not None:\n",
    "        print(\n",
    "            \"\\nTest: Test loss: {:.4f} \\t Test RMSE: {:.4f}\\n\".format(test_loss, test_loss ** 2) # type: ignore\n",
    "        )\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': []\n",
    "}\n",
    "for epoch in tqdm(range(1, 6)):\n",
    "    history['train_loss'].append(train(model, criterion, optimizer, train_loader, device, epoch, print_every=1000))\n",
    "    history['val_loss'].append(test(model, criterion, device, valid_loader))\n",
    "\n",
    "history['train_loss'] = np.array(history['train_loss'])\n",
    "history['val_loss'] = np.array(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['train_loss'] = np.array(history['train_loss'])\n",
    "history['val_loss'] = np.array(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label=\"Training Loss\")\n",
    "    plt.plot(history['val_loss'], label=\"Validation Loss\")\n",
    "    plt.title(\"Loss Curve\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_loss'] ** 0.5, label=\"Training RMSE\")\n",
    "    plt.plot(history['val_loss'] ** 0.5, label=\"Validation RMSE\")\n",
    "    plt.title(\"RMSE Curve\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.assign(item_cnt_month=train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miloszhanczyk/Documents/uv/MOW_2/lab/sales_forecasting/.venv/lib/python3.10/site-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/Users/miloszhanczyk/Documents/uv/MOW_2/lab/sales_forecasting/.venv/lib/python3.10/site-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>general_item_category_id</th>\n",
       "      <th>date_month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>lagged_1</th>\n",
       "      <th>lagged_2</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_shop_item_item_price_lag_1</th>\n",
       "      <th>avg_shop_item_item_cnt_day_lag_1</th>\n",
       "      <th>avg_item_item_price_lag_1</th>\n",
       "      <th>avg_item_item_cnt_day_lag_1</th>\n",
       "      <th>avg_shop_item_category_item_price_lag_1</th>\n",
       "      <th>avg_shop_item_category_item_cnt_day_lag_1</th>\n",
       "      <th>avg_item_category_item_price_lag_1</th>\n",
       "      <th>avg_item_category_item_cnt_day_lag_1</th>\n",
       "      <th>months_since_last_buy</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>270.50</td>\n",
       "      <td>1.163086</td>\n",
       "      <td>264.00</td>\n",
       "      <td>1.080078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>-0.707031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>263.50</td>\n",
       "      <td>1.150391</td>\n",
       "      <td>265.50</td>\n",
       "      <td>1.080078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>263.75</td>\n",
       "      <td>1.170898</td>\n",
       "      <td>263.75</td>\n",
       "      <td>1.087891</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.258789</td>\n",
       "      <td>-0.965820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>262.25</td>\n",
       "      <td>1.138672</td>\n",
       "      <td>264.00</td>\n",
       "      <td>1.089844</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>262.50</td>\n",
       "      <td>1.228516</td>\n",
       "      <td>262.00</td>\n",
       "      <td>1.131836</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29460948</th>\n",
       "      <td>59</td>\n",
       "      <td>22169</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.069336</td>\n",
       "      <td>1042.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1093.00</td>\n",
       "      <td>1.047852</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29460949</th>\n",
       "      <td>59</td>\n",
       "      <td>22169</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>0.258789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.069336</td>\n",
       "      <td>489.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1130.00</td>\n",
       "      <td>1.031250</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29460950</th>\n",
       "      <td>59</td>\n",
       "      <td>22169</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.069336</td>\n",
       "      <td>1080.00</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>938.50</td>\n",
       "      <td>1.047852</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29460951</th>\n",
       "      <td>59</td>\n",
       "      <td>22169</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>-0.258789</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.069336</td>\n",
       "      <td>553.00</td>\n",
       "      <td>1.151367</td>\n",
       "      <td>738.50</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29460952</th>\n",
       "      <td>59</td>\n",
       "      <td>22169</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>299.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.069336</td>\n",
       "      <td>822.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>888.50</td>\n",
       "      <td>1.034180</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21137776 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          shop_id  item_id  city_id  item_category_id  \\\n",
       "0               0        0        0                40   \n",
       "1               0        0        0                40   \n",
       "2               0        0        0                40   \n",
       "3               0        0        0                40   \n",
       "4               0        0        0                40   \n",
       "...           ...      ...      ...               ...   \n",
       "29460948       59    22169       30                69   \n",
       "29460949       59    22169       30                69   \n",
       "29460950       59    22169       30                69   \n",
       "29460951       59    22169       30                69   \n",
       "29460952       59    22169       30                69   \n",
       "\n",
       "          general_item_category_id  date_month  month_sin  month_cos  \\\n",
       "0                               11           8   0.866211  -0.500000   \n",
       "1                               11           9   0.707031  -0.707031   \n",
       "2                               11          10   0.500000  -0.866211   \n",
       "3                               11          11   0.258789  -0.965820   \n",
       "4                               11           0   0.000000   1.000000   \n",
       "...                            ...         ...        ...        ...   \n",
       "29460948                        14           4   0.866211   0.500000   \n",
       "29460949                        14           5   0.965820   0.258789   \n",
       "29460950                        14           6   1.000000   0.000000   \n",
       "29460951                        14           7   0.965820  -0.258789   \n",
       "29460952                        14           8   0.866211  -0.500000   \n",
       "\n",
       "          lagged_1  lagged_2  ...  avg_shop_item_item_price_lag_1  \\\n",
       "0                0         0  ...                           169.0   \n",
       "1                0         0  ...                           169.0   \n",
       "2                0         0  ...                           169.0   \n",
       "3                0         0  ...                           169.0   \n",
       "4                0         0  ...                           169.0   \n",
       "...            ...       ...  ...                             ...   \n",
       "29460948         0         0  ...                           299.0   \n",
       "29460949         0         0  ...                           299.0   \n",
       "29460950         0         0  ...                           299.0   \n",
       "29460951         0         0  ...                           299.0   \n",
       "29460952         0         0  ...                           299.0   \n",
       "\n",
       "          avg_shop_item_item_cnt_day_lag_1  avg_item_item_price_lag_1  \\\n",
       "0                                      1.0                     4488.0   \n",
       "1                                      1.0                     4488.0   \n",
       "2                                      1.0                     4488.0   \n",
       "3                                      1.0                     4488.0   \n",
       "4                                      1.0                     4488.0   \n",
       "...                                    ...                        ...   \n",
       "29460948                               1.0                      169.0   \n",
       "29460949                               1.0                      169.0   \n",
       "29460950                               1.0                      169.0   \n",
       "29460951                               1.0                      169.0   \n",
       "29460952                               1.0                      169.0   \n",
       "\n",
       "          avg_item_item_cnt_day_lag_1  \\\n",
       "0                            1.000000   \n",
       "1                            1.000000   \n",
       "2                            1.000000   \n",
       "3                            1.000000   \n",
       "4                            1.000000   \n",
       "...                               ...   \n",
       "29460948                     1.069336   \n",
       "29460949                     1.069336   \n",
       "29460950                     1.069336   \n",
       "29460951                     1.069336   \n",
       "29460952                     1.069336   \n",
       "\n",
       "          avg_shop_item_category_item_price_lag_1  \\\n",
       "0                                          270.50   \n",
       "1                                          263.50   \n",
       "2                                          263.75   \n",
       "3                                          262.25   \n",
       "4                                          262.50   \n",
       "...                                           ...   \n",
       "29460948                                  1042.00   \n",
       "29460949                                   489.00   \n",
       "29460950                                  1080.00   \n",
       "29460951                                   553.00   \n",
       "29460952                                   822.50   \n",
       "\n",
       "          avg_shop_item_category_item_cnt_day_lag_1  \\\n",
       "0                                          1.163086   \n",
       "1                                          1.150391   \n",
       "2                                          1.170898   \n",
       "3                                          1.138672   \n",
       "4                                          1.228516   \n",
       "...                                             ...   \n",
       "29460948                                   1.000000   \n",
       "29460949                                   1.000000   \n",
       "29460950                                   1.125000   \n",
       "29460951                                   1.151367   \n",
       "29460952                                   1.000000   \n",
       "\n",
       "          avg_item_category_item_price_lag_1  \\\n",
       "0                                     264.00   \n",
       "1                                     265.50   \n",
       "2                                     263.75   \n",
       "3                                     264.00   \n",
       "4                                     262.00   \n",
       "...                                      ...   \n",
       "29460948                             1093.00   \n",
       "29460949                             1130.00   \n",
       "29460950                              938.50   \n",
       "29460951                              738.50   \n",
       "29460952                              888.50   \n",
       "\n",
       "          avg_item_category_item_cnt_day_lag_1  months_since_last_buy  \\\n",
       "0                                     1.080078                      0   \n",
       "1                                     1.080078                      1   \n",
       "2                                     1.087891                      2   \n",
       "3                                     1.089844                      3   \n",
       "4                                     1.131836                      4   \n",
       "...                                        ...                    ...   \n",
       "29460948                              1.047852                     14   \n",
       "29460949                              1.031250                     15   \n",
       "29460950                              1.047852                     16   \n",
       "29460951                              1.071289                     17   \n",
       "29460952                              1.034180                     18   \n",
       "\n",
       "          item_cnt_month  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "29460948               0  \n",
       "29460949               0  \n",
       "29460950               0  \n",
       "29460951               0  \n",
       "29460952               0  \n",
       "\n",
       "[21137776 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>general_item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194531</th>\n",
       "      <td>59</td>\n",
       "      <td>22165</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194532</th>\n",
       "      <td>59</td>\n",
       "      <td>22166</td>\n",
       "      <td>30</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194533</th>\n",
       "      <td>59</td>\n",
       "      <td>22167</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194534</th>\n",
       "      <td>59</td>\n",
       "      <td>22168</td>\n",
       "      <td>30</td>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194535</th>\n",
       "      <td>59</td>\n",
       "      <td>22169</td>\n",
       "      <td>30</td>\n",
       "      <td>69</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1194536 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         shop_id  item_id  city_id  item_category_id  general_item_category_id\n",
       "0              0        0        0                40                        11\n",
       "1              0        1        0                76                        15\n",
       "2              0        2        0                40                        11\n",
       "3              0        3        0                40                        11\n",
       "4              0        4        0                40                        11\n",
       "...          ...      ...      ...               ...                       ...\n",
       "1194531       59    22165       30                31                         8\n",
       "1194532       59    22166       30                54                        12\n",
       "1194533       59    22167       30                49                        12\n",
       "1194534       59    22168       30                62                        14\n",
       "1194535       59    22169       30                69                        14\n",
       "\n",
       "[1194536 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_cols = ['shop_id', 'item_id', 'city_id', 'item_category_id', 'general_item_category_id']\n",
    "X_train[embed_cols].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cols = np.setdiff1d(X_train.columns, embed_cols + [\"item_cnt_month\"])\n",
    "embed_cols = ['shop_id', 'item_id', 'city_id', 'item_category_id', 'general_item_category_id']\n",
    "embed_entity_index = X_train[embed_cols].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "vector_tuples = []\n",
    "for (shop_id, item_id), group in X_train.groupby(['shop_id', 'item_id']):\n",
    "    embed_entities = embed_entity_index[(embed_entity_index.shop_id == shop_id) & (embed_entity_index.item_id == item_id)].values\n",
    "    seq_matrix = group[seq_cols].values\n",
    "    target_array = group['item_cnt_month'].values\n",
    "    vector_tuples.append((embed_entities, seq_matrix, target_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('.data/vector_tuples.pkl', 'wb') as f:\n",
    "    pickle.dump(vector_tuples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(matrices):\n",
    "    L = len(matrices)\n",
    "    D = matrices[0].shape[1]\n",
    "    K = max(matrix.shape[0] for matrix in matrices)\n",
    "\n",
    "    padded_tensor = torch.zeros((L, K, D), dtype=torch.float32)\n",
    "\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        n = matrix.shape[0]\n",
    "        padded_tensor[i, :n, :] = torch.tensor(matrix, dtype=torch.float32)\n",
    "    return padded_tensor\n",
    "\n",
    "def pad_sequences1d(sequences):\n",
    "    L = len(sequences)\n",
    "    K = max(len(seq) for seq in sequences)\n",
    "\n",
    "    padded_tensor = torch.zeros((L, K), dtype=torch.float32)\n",
    "\n",
    "    for i, seq in enumerate(sequences):\n",
    "        n = len(seq)\n",
    "        padded_tensor[i, :n] = torch.tensor(seq, dtype=torch.float32)\n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesDataset(Dataset):\n",
    "    def __init__(self, df_tuples_array: list[tuple[np.ndarray, np.ndarray, np.ndarray]]):\n",
    "        self.df = df_tuples_array\n",
    "        self.embed_entities = torch.tensor([x[0] for x in self.df], dtype=torch.long).squeeze(1)\n",
    "        self.seq_matr = pad_sequences([torch.tensor(x[1], dtype=torch.float32) for x in self.df])\n",
    "        \n",
    "        self.target_lengths = torch.tensor([len(x[2]) for x in self.df], dtype=torch.long)\n",
    "        self.target_last_values = torch.tensor([x[2][-1] for x in self.df], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.embed_entities[idx], \n",
    "                self.seq_matr[idx],\n",
    "                self.target_lengths[idx], \n",
    "                self.target_last_values[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SalesPredictionModel(nn.Module):\n",
    "    def __init__(self, emb_cardinality, embedding_size, dropout_rate, seq_input_size):\n",
    "        super(SalesPredictionModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for categorical variables\n",
    "        self._embedding_size = embedding_size\n",
    "        self._emb_cardinality = emb_cardinality\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_embeddings, self._embedding_size) \n",
    "            for num_embeddings in self._emb_cardinality\n",
    "        ])\n",
    "        self._emb_dim_sum = len(self._emb_cardinality) * self._embedding_size\n",
    "\n",
    "        # LSTM layer\n",
    "        self._lstm_input_size = seq_input_size\n",
    "        self._lstm_hidden_size = 2 * embedding_size\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self._lstm_input_size,\n",
    "            hidden_size=self._lstm_hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self._fc_input_size = self._lstm_hidden_size + self._emb_dim_sum\n",
    "        self.fc = nn.Linear(self._fc_input_size, 1)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, embed, seq, tgt_ix):\n",
    "        # Embedding layers\n",
    "        embedded_features = [embedding(embed[:, i]) for i, embedding in enumerate(self.embeddings)]\n",
    "        emb_tensors = torch.cat(embedded_features, dim=1)\n",
    "        #emb_tensors = self.dropout(emb_tensors) \n",
    "\n",
    "        # LSTM\n",
    "        _, (lstm_hidden_state, _) = self.lstm(seq)\n",
    "        lstm_hidden_state = lstm_hidden_state[-1]\n",
    "\n",
    "        # Concatenate embeddings and LSTM output\n",
    "        concatenated = torch.cat([emb_tensors, lstm_hidden_state], dim=1)\n",
    "\n",
    "        output = self.fc(concatenated)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/v5bcwy852z121w7pz8m7sypr0000gn/T/ipykernel_67271/1370659372.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_tensor[i, :n, :] = torch.tensor(matrix, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_dataset = SalesDataset(vector_tuples)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# val_dataset = SalesDataset(df_val)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Parameters\n",
    "emb_cardinality = X_train.shop_id.max()+1, X_train.item_id.max()+1, X_train.city_id.max()+1, X_train.item_category_id.max()+1, X_train.general_item_category_id.max()+1\n",
    "embedding_size = 8\n",
    "dropout_rate = 0.1\n",
    "seq_input_size = 26\n",
    "lr = 1e-3\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = SalesPredictionModel(emb_cardinality, embedding_size, dropout_rate, seq_input_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalesPredictionModel(\n",
       "  (embeddings): ModuleList(\n",
       "    (0): Embedding(60, 8)\n",
       "    (1): Embedding(22170, 8)\n",
       "    (2): Embedding(31, 8)\n",
       "    (3): Embedding(84, 8)\n",
       "    (4): Embedding(20, 8)\n",
       "  )\n",
       "  (lstm): LSTM(26, 16, batch_first=True)\n",
       "  (fc): Linear(in_features=56, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module, \n",
    "    loss_fn: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    device: torch.device, \n",
    "    epoch: int, \n",
    "    print_every: None | int = None\n",
    ") -> float:\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        embed, seq, tgt_ix, target = batch\n",
    "        optimizer.zero_grad()\n",
    "        output = model(embed, seq, tgt_ix)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_item = loss.detach().cpu().item()\n",
    "\n",
    "        if print_every is not None and batch_idx % print_every == 0:\n",
    "            print(\n",
    "                \"Train (Batch): [{}/{} ({:.0f}%)]\\tTrain Loss: {:.4f} \\tTrain RMSE: {:.4f}\".format(\n",
    "                    batch_idx * len([batch[0]]), len(train_loader.dataset), 100.0 * batch_idx / len(train_loader), loss_item, loss_item ** 0.5\n",
    "                ) # type: ignore\n",
    "            )\n",
    "        train_loss += loss_item\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: nn.Module, \n",
    "    loss_fn: Callable,\n",
    "    device: torch.device,\n",
    "    test_loader: DataLoader, \n",
    "    print_every: None | int = None\n",
    ") -> float:\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss =  loss_fn(output, target, reduction=\"sum\")\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    if print_every is not None:\n",
    "        print(\n",
    "            \"\\nTest: Test loss: {:.4f} \\t Test RMSE: {:.4f}\\n\".format(test_loss, test_loss ** 2) # type: ignore\n",
    "        )\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/miloszhanczyk/Documents/uv/MOW_2/lab/sales_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([1024])) that is different to the input size (torch.Size([1024, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Batch): [0/1194536 (0%)]\tTrain Loss: 0.8511 \tTrain RMSE: 0.9226\n",
      "Train (Batch): [1000/1194536 (86%)]\tTrain Loss: 0.2297 \tTrain RMSE: 0.4793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miloszhanczyk/Documents/uv/MOW_2/lab/sales_forecasting/.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([552])) that is different to the input size (torch.Size([552, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      " 20%|██        | 1/5 [00:16<01:07, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Batch): [0/1194536 (0%)]\tTrain Loss: 0.0437 \tTrain RMSE: 0.2090\n",
      "Train (Batch): [1000/1194536 (86%)]\tTrain Loss: 0.0692 \tTrain RMSE: 0.2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:33<00:49, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Batch): [0/1194536 (0%)]\tTrain Loss: 0.5377 \tTrain RMSE: 0.7333\n",
      "Train (Batch): [1000/1194536 (86%)]\tTrain Loss: 0.0770 \tTrain RMSE: 0.2775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:49<00:32, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Batch): [0/1194536 (0%)]\tTrain Loss: 0.1807 \tTrain RMSE: 0.4251\n",
      "Train (Batch): [1000/1194536 (86%)]\tTrain Loss: 0.0389 \tTrain RMSE: 0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:05<00:16, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (Batch): [0/1194536 (0%)]\tTrain Loss: 0.8768 \tTrain RMSE: 0.9364\n",
      "Train (Batch): [1000/1194536 (86%)]\tTrain Loss: 0.0635 \tTrain RMSE: 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:22<00:00, 16.41s/it]\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': []\n",
    "}\n",
    "for epoch in tqdm(range(1, 6)):\n",
    "    history['train_loss'].append(train(model, criterion, optimizer, train_loader, device, epoch, print_every=1000))\n",
    "    #history['val_loss'].append(test(model, criterion, device, valid_loader))\n",
    "\n",
    "history['train_loss'] = np.array(history['train_loss'])\n",
    "#history['val_loss'] = np.array(history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset\n",
    "train_dataset = SalesDataset(df_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Parameters\n",
    "num_shops = df_val['shop_id'].max() + 1        # Example: total unique shops\n",
    "num_items = df_val['item_id'].max() + 1       # Example: total unique items\n",
    "num_categories = df_val['item_category_id'].max() + 1    # Example: total unique categories\n",
    "\n",
    "# Instantiate the model\n",
    "model = SalesPredictionModel(num_shops, num_items, num_categories, embedding_size, dropout_rate=dropout_rate)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 33\n",
    "\n",
    "history = {\n",
    "    'train_loss': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        shop_ids, item_ids, category_ids, sales_arrays, targets = batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(shop_ids, item_ids, category_ids, sales_arrays)\n",
    "        loss = criterion(predictions, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    history['train_loss'].append(running_loss / len(train_loader))    \n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.2f} \\\n",
    "[rmse: {np.sqrt(running_loss/len(train_loader)):.2f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_raw = pd.read_csv(\".data/test.csv\", index_col=[0]).assign(date_block_num=34, item_cnt_month=np.nan)\n",
    "df_test_vectors = transform_data_to_features(pd.concat([test_split_featurized, df_test_raw]), 35)\n",
    "df_test = df_test_vectors.merge(pd.read_csv(\".data/items.csv\")[['item_id', 'item_category_id']], on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SalesDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_dataset)):\n",
    "        elem = (_.unsqueeze(0) for _ in test_dataset[i])\n",
    "        shop_ids, item_ids, category_ids, sales_arrays, _ = elem\n",
    "\n",
    "        predictions = model(shop_ids, item_ids, category_ids, sales_arrays)\n",
    "        preds.append(predictions.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = df_test_raw \\\n",
    "    .reset_index()[['ID', 'shop_id', 'item_id']] \\\n",
    "    .merge(\n",
    "        df_test.assign(predictions=preds)[['shop_id', 'item_id', 'predictions']], \n",
    "        on=['shop_id', 'item_id'], \n",
    "        how='left'\n",
    "    )[['ID', 'predictions']] \\\n",
    "    .rename(columns={'predictions': 'item_cnt_month'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission['item_cnt_month'] = df_submission['item_cnt_month'].clip(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv(\".data/submission_lstm2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
